from fastapi import FastAPI, HTTPException, Request
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
from pydantic import BaseModel
import os
import json
import re
import random
from dotenv import load_dotenv
from typing import Dict, Any, Optional

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# å¯¼å…¥é…ç½®ç®¡ç†
from src.core.app_config import AppConfig

# é…ç½®LangSmithï¼ˆå¿…é¡»åœ¨å¯¼å…¥agentä¹‹å‰è®¾ç½®ï¼‰
AppConfig.setup_langsmith()

# ä¿®å¤å¯¼å…¥è·¯å¾„
from src.core.agent import build_agent
from src.core.severity_analyzer import SeverityResult, severity_analyzer
from src.memory.memory_manager import SmartMemoryManager

app = FastAPI(title="Anti Love Brain - æ‹½å§ Agent")

# æŒ‚è½½é™æ€æ–‡ä»¶
app.mount("/static", StaticFiles(directory="static"), name="static")

# æ‰“å°é…ç½®ä¿¡æ¯
AppConfig.print_startup_info()

def get_user_identifier(request: Request) -> str:
    """ç»Ÿä¸€çš„ç”¨æˆ·æ ‡è¯†è·å–å‡½æ•°"""
    print(f"[DEBUG] ===== ç”¨æˆ·æ ‡è¯†è·å– =====")
    print(f"[DEBUG] ENABLE_IP_ISOLATION: {AppConfig.ENABLE_IP_ISOLATION}")
    print(f"[DEBUG] IS_DEVELOPMENT: {AppConfig.IS_DEVELOPMENT}")
    print(f"[DEBUG] RAILWAY_ENVIRONMENT: {os.getenv('RAILWAY_ENVIRONMENT')}")
    print(f"[DEBUG] PORT: {os.getenv('PORT')}")
    
    if not AppConfig.ENABLE_IP_ISOLATION:
        print(f"[DEBUG] IPéš”ç¦»ç¦ç”¨ï¼Œä½¿ç”¨default_user")
        return "default_user"
    
    # åœ¨å¼€å‘ç¯å¢ƒä¸­ï¼Œå¯ä»¥ä½¿ç”¨å›ºå®šæ ‡è¯†ç¬¦ä»¥ä¾¿è°ƒè¯•
    if AppConfig.IS_DEVELOPMENT:
        # å¼€å‘ç¯å¢ƒä¸‹ä¸ºäº†æ–¹ä¾¿è°ƒè¯•ï¼Œä½¿ç”¨å›ºå®šç”¨æˆ·æ ‡è¯†
        print(f"[DEBUG] å¼€å‘ç¯å¢ƒï¼Œä½¿ç”¨dev_user")
        return "dev_user"
    
    # ç”Ÿäº§ç¯å¢ƒï¼šä¼˜å…ˆä½¿ç”¨X-Forwarded-Forå¤´éƒ¨ï¼Œé¿å…VPNå¯¼è‡´çš„IPå˜åŒ–é—®é¢˜
    # å¦‚æœVPNå¯¼è‡´IPé¢‘ç¹å˜åŒ–ï¼Œå¯ä»¥è€ƒè™‘ä½¿ç”¨å…¶ä»–ç¨³å®šçš„æ ‡è¯†æ–¹å¼
    user_ip = request.headers.get("X-Forwarded-For", request.client.host)
    if "," in user_ip:
        # X-Forwarded-Forå¯èƒ½åŒ…å«å¤šä¸ªIPï¼Œå–ç¬¬ä¸€ä¸ª
        user_ip = user_ip.split(",")[0].strip()
    
    # VPNå…¼å®¹æ–¹æ¡ˆï¼šå¦‚æœæ£€æµ‹åˆ°IPå˜åŒ–é¢‘ç¹ï¼Œä½¿ç”¨æ›´ç¨³å®šçš„æ ‡è¯†
    # è¿™é‡Œå¯ä»¥æ·»åŠ åŸºäºUser-Agentæˆ–å…¶ä»–ç¨³å®šç‰¹å¾çš„æ ‡è¯†é€»è¾‘
    # æš‚æ—¶å…ˆä½¿ç”¨IPï¼Œä½†æ·»åŠ VPNæ£€æµ‹æç¤º
    
    print(f"[DEBUG] ç”Ÿäº§ç¯å¢ƒï¼Œä½¿ç”¨IP: {user_ip}")
    print(f"[DEBUG] X-Forwarded-For: {request.headers.get('X-Forwarded-For', 'None')}")
    print(f"[DEBUG] Client Host: {request.client.host}")
    print(f"[DEBUG] User-Agent: {request.headers.get('User-Agent', 'None')[:50]}...")
    print(f"[DEBUG] ===== ç”¨æˆ·æ ‡è¯†è·å–å®Œæˆ =====")
    return user_ip

# ç”¨æˆ·è®°å¿†ç®¡ç†å™¨ - ç®€åŒ–ä¸ºç›´æ¥ä½¿ç”¨Agentæ¶æ„
user_memory_managers: Dict[str, Any] = {}

# æµ·ç‹å¯¹æˆ˜å†å²ç®¡ç† - åªä¿å­˜ä¸Šä¸€è½®å¯¹è¯
seaking_last_conversations: Dict[str, str] = {}

class ChatRequest(BaseModel):
    message: str
    persona: str = ""
    history: list = []
    # ğŸŒŠ æ–°å¢æŒ‰é’®å‚æ•°æ”¯æŒ
    button_type: Optional[str] = None  # "ğŸŒŠå¯¹æˆ˜æµ·ç‹" | "ğŸµåèŒ¶è‰ºå¤§å¸ˆ" | "ğŸŒˆå†³æˆ˜é€šè®¯å½•ä¹‹å·…" | "æ­£å¸¸èŠå¤©"
    seaking_score: Optional[int] = 0  # æµ·ç‹å¯¹æˆ˜å¾—åˆ†
    is_first_seaking: Optional[bool] = True  # æ˜¯å¦é¦–æ¬¡æµ·ç‹å¯¹æˆ˜
    # ğŸŒŠ æ–°å¢äººè®¾å‚æ•°æ”¯æŒ
    gender: Optional[str] = None  # æµ·ç‹æ€§åˆ«
    user_gender: Optional[str] = None  # ç”¨æˆ·æ€§åˆ«
    challenge_type: Optional[str] = None  # æŒ‘æˆ˜ç±»å‹
    description: Optional[str] = None  # äººè®¾æè¿°
    style: Optional[str] = None  # äººè®¾é£æ ¼
    weakness: Optional[str] = None  # äººè®¾å¼±ç‚¹

def get_memory_manager(user_ip: str):
    """è·å–ç”¨æˆ·çš„è®°å¿†ç®¡ç†å™¨å’ŒAgent"""
    if user_ip not in user_memory_managers:
        # ç›´æ¥åˆ›å»ºè®°å¿†ç®¡ç†å™¨
        memory_manager = SmartMemoryManager(
            max_tokens=1500,
            summary_trigger_ratio=0.8
        )
        
        # åˆ›å»ºAgent
        agent = build_agent(memory_manager)
        
        # å­˜å‚¨è®°å¿†ç®¡ç†å™¨å’ŒAgent
        user_memory_managers[user_ip] = {
            "memory_manager": memory_manager,
            "agent": agent
        }
    return user_memory_managers[user_ip]

def generate_seaking_persona(button_type: str) -> Dict[str, Any]:
    """æ ¹æ®æŒ‰é’®ç±»å‹ç”Ÿæˆéšæœºæµ·ç‹äººè®¾"""
    personas_data = AppConfig.load_personas()
    
    if button_type not in personas_data:
        return {
            "persona": "ENTJ-é«˜é˜¶PUA",
            "gender": "ç”·",
            "user_gender": "å¥³",
            "challenge_type": "æµ·ç‹å¯¹æˆ˜",
            "description": "ä»¥åˆºæ¿€ã€æ–°é²œæ„Ÿåˆ¶é€ æƒ…ç»ªè¿‡å±±è½¦ï¼Œæ“…é•¿ç”¨â€œä¸´æ—¶è®¡åˆ’+é«˜é¢‘é‚€çº¦â€å»ºç«‹ä¼˜åŠ¿åœ°ä½ï¼Œä¹ æƒ¯åœ¨ä¸´ç•Œäº²å¯†å‰åˆ‡æ¢ç›®æ ‡ã€‚",
            "style": "å¤œç”Ÿæ´»è¾¾äººã€è¿åŠ¨æ§ã€æ“…é•¿å³å…´å†³ç­–ä¸è‚¢ä½“è¯­è¨€",
            "weakness": "è€å¿ƒå·®ã€åŒå€¦å¿«ï¼Œæ·±åº¦å…³ç³»ç»´æŠ¤èƒ½åŠ›ä½"
        }
    
    config = personas_data[button_type]
    if "personas" in config and config["personas"]:
        selected_persona = random.choice(config["personas"])
        return {
            "persona": selected_persona.get("name", "ENTJ-é«˜é˜¶PUA"),
            "gender": selected_persona.get("gender", "ç”·"),
            "user_gender": selected_persona.get("user_gender", "å¥³"),
            "challenge_type": selected_persona.get("challenge_type", "æµ·ç‹å¯¹æˆ˜"),
            "description": selected_persona.get("description", "ä»¥åˆºæ¿€ã€æ–°é²œæ„Ÿåˆ¶é€ æƒ…ç»ªè¿‡å±±è½¦ï¼Œæ“…é•¿ç”¨â€œä¸´æ—¶è®¡åˆ’+é«˜é¢‘é‚€çº¦â€å»ºç«‹ä¼˜åŠ¿åœ°ä½ï¼Œä¹ æƒ¯åœ¨ä¸´ç•Œäº²å¯†å‰åˆ‡æ¢ç›®æ ‡ã€‚"),
            "style": selected_persona.get("style", "å¤œç”Ÿæ´»è¾¾äººã€è¿åŠ¨æ§ã€æ“…é•¿å³å…´å†³ç­–ä¸è‚¢ä½“è¯­è¨€"),
            "weakness": selected_persona.get("weakness", "è€å¿ƒå·®ã€åŒå€¦å¿«ï¼Œæ·±åº¦å…³ç³»ç»´æŠ¤èƒ½åŠ›ä½")
        }
    
    # é™çº§å¤„ç†
    return {
        "persona": "ENTJ-é«˜é˜¶PUA",
        "gender": "ç”·",
        "user_gender": "å¥³",
        "challenge_type": "æµ·ç‹å¯¹æˆ˜",
        "description": "ä»¥åˆºæ¿€ã€æ–°é²œæ„Ÿåˆ¶é€ æƒ…ç»ªè¿‡å±±è½¦ï¼Œæ“…é•¿ç”¨â€œä¸´æ—¶è®¡åˆ’+é«˜é¢‘é‚€çº¦â€å»ºç«‹ä¼˜åŠ¿åœ°ä½ï¼Œä¹ æƒ¯åœ¨ä¸´ç•Œäº²å¯†å‰åˆ‡æ¢ç›®æ ‡ã€‚",
        "style": "å¤œç”Ÿæ´»è¾¾äººã€è¿åŠ¨æ§ã€æ“…é•¿å³å…´å†³ç­–ä¸è‚¢ä½“è¯­è¨€",
        "weakness": "è€å¿ƒå·®ã€åŒå€¦å¿«ï¼Œæ·±åº¦å…³ç³»ç»´æŠ¤èƒ½åŠ›ä½"
    }

def parse_seaking_score(ai_response: str, prev_score: int, is_first_round: bool = False) -> tuple[int, bool]:
    """ä»AIå›å¤ä¸­è§£æå¾—åˆ†å’Œèƒœåˆ©çŠ¶æ€"""
    try:
        print(f"[DEBUG] è§£æå¾—åˆ† - AIå›å¤: {ai_response[:200]}...")
        print(f"[DEBUG] è§£æå¾—åˆ† - ä¸Šè½®å¾—åˆ†: {prev_score}")
        
        # æ£€æŸ¥æ˜¯å¦é€šå…³
        if "ğŸ‰æ­å–œæŒ‘æˆ˜æˆåŠŸ" in ai_response or "æ­å–œé€šå…³" in ai_response:
            print(f"[DEBUG] æ£€æµ‹åˆ°é€šå…³ä¿¡æ¯")
            return 100, True
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç¬¬ä¸€è½®å¯¹è¯ï¼ˆåŸºäºå¯¹è¯å†å²åˆ¤æ–­ï¼‰
        if is_first_round:
            print(f"[DEBUG] æ£€æµ‹åˆ°ç¬¬ä¸€è½®å¯¹è¯ï¼Œä¿æŒå¾—åˆ†ä¸º0")
            return 0, False
        
        # æ›´ç²¾ç¡®çš„å¾—åˆ†åŒ¹é…æ¨¡å¼ - ä¸“é—¨åŒ¹é…æ‹½å§æ—ç™½ä¸­çš„å¾—åˆ†
        score_patterns = [
            r'ã€æ‹½å§æ—ç™½ã€‘.*?å½“å‰å¾—åˆ†[ï¼š:]\s*(\d+)',  # åŒ¹é…æ‹½å§æ—ç™½ä¸­çš„å½“å‰å¾—åˆ†
            r'å½“å‰å¾—åˆ†[ï¼š:]\s*(\d+)',  # åŒ¹é…å½“å‰å¾—åˆ†
            r'å¾—åˆ†[ï¼š:]\s*(\d+)'  # åŒ¹é…å¾—åˆ†
        ]
        
        for pattern in score_patterns:
            match = re.search(pattern, ai_response)
            if match:
                score = int(match.group(1))
                print(f"[DEBUG] æˆåŠŸè§£æå¾—åˆ†: {score} (ä½¿ç”¨æ¨¡å¼: {pattern})")
                return score, score >= 100
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ˜ç¡®çš„å¾—åˆ†ï¼Œä¿æŒåŸå¾—åˆ†ä¸å˜
        print(f"[DEBUG] æœªæ‰¾åˆ°å¾—åˆ†ä¿¡æ¯ï¼Œä¿æŒåŸå¾—åˆ†: {prev_score}")
        return prev_score, prev_score >= 100
        
    except Exception as e:
        print(f"[Error] Parse seaking score failed: {e}")
        print(f"[DEBUG] å¼‚å¸¸æƒ…å†µï¼Œè¿”å›åŸå¾—åˆ†: {prev_score}")
        return prev_score, prev_score >= 100

@app.get("/")
async def read_index():
    """ä¸»é¡µé¢"""
    response = FileResponse('static/index_modern.html')
    if AppConfig.IS_DEVELOPMENT:
        response.headers["Cache-Control"] = "no-cache, no-store, must-revalidate"
        response.headers["Pragma"] = "no-cache"
        response.headers["Expires"] = "0"
    return response

@app.get("/chat")
async def read_chat():
    """èŠå¤©é¡µé¢"""
    response = FileResponse('static/chat.html')
    if AppConfig.IS_DEVELOPMENT:
        response.headers["Cache-Control"] = "no-cache, no-store, must-revalidate"
        response.headers["Pragma"] = "no-cache"
        response.headers["Expires"] = "0"
    return response

@app.post("/chat")
async def chat(request: ChatRequest, req: Request):
    """èŠå¤©ç«¯ç‚¹ - æ”¯æŒç›´æ¥æµ·ç‹å¯¹æˆ˜å’Œæ­£å¸¸Agentæ¨¡å¼"""
    user_ip = get_user_identifier(req)
    
    try:
        user_session = get_memory_manager(user_ip)
        memory_manager = user_session["memory_manager"]
        agent = user_session["agent"]
        
        # ğŸŒŠ æ£€æŸ¥æ˜¯å¦ä¸ºæµ·ç‹å¯¹æˆ˜æ¨¡å¼
        if request.button_type and AppConfig.is_seaking_mode(request.button_type):
            return await handle_seaking_mode(request, memory_manager, user_ip)
        
        # æ­£å¸¸èŠå¤©æ¨¡å¼ - ä½¿ç”¨åŒæ­¥ä¼˜åŒ–é€»è¾‘
        return handle_normal_chat(request, memory_manager, agent)
        
    except Exception as e:
        print(f"[Error] Chat processing failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))

async def handle_seaking_mode(request: ChatRequest, memory_manager, user_ip: str):
    """å¤„ç†æµ·ç‹å¯¹æˆ˜æ¨¡å¼"""
    print(f"=== handle_seaking_mode è¢«è°ƒç”¨ ===")
    print(f"è¯·æ±‚å‚æ•°: button_type={request.button_type}, persona={request.persona}")
    try:
        # ä½¿ç”¨å‰ç«¯ä¼ é€’çš„äººè®¾ä¿¡æ¯ï¼Œå¦‚æœæ²¡æœ‰åˆ™ç”Ÿæˆæ–°çš„
        if request.persona and request.gender and request.user_gender and request.challenge_type and request.description and request.style and request.weakness:
            # å‰ç«¯å·²ä¼ é€’å®Œæ•´äººè®¾ä¿¡æ¯ï¼Œç›´æ¥ä½¿ç”¨
            persona_config = {
                "persona": request.persona,
                "gender": request.gender,
                "user_gender": request.user_gender,
                "challenge_type": request.challenge_type,
                "description": request.description,
                "style": request.style,
                "weakness": request.weakness
            }
            print(f"[DEBUG] ä½¿ç”¨å‰ç«¯ä¼ é€’çš„äººè®¾: {request.persona}")
        else:
            # ç”Ÿæˆæµ·ç‹äººè®¾ï¼ˆé€šå¸¸åªåœ¨ç¬¬ä¸€æ¬¡åˆ‡æ¢æ¨¡å¼æ—¶å‘ç”Ÿï¼‰
            persona_config = generate_seaking_persona(request.button_type)
            print(f"[DEBUG] ç”Ÿæˆæ–°çš„éšæœºäººè®¾: {persona_config['persona']}")
        
        # ä½¿ç”¨æ–°çš„SeakingChain
        from src.tools.seaking import SeakingChain
        seaking_chain = SeakingChain()
        
        # è·å–ä¸Šä¸€è½®å¯¹è¯ - ä½¿ç”¨åç«¯ç‹¬ç«‹ç»´æŠ¤çš„æµ·ç‹å¯¹è¯å†å²
        last_conversation = seaking_last_conversations.get(user_ip, "ï¼ˆè¿™æ˜¯ç¬¬ä¸€è½®å¯¹è¯ï¼‰")
        is_first_round = last_conversation == "ï¼ˆè¿™æ˜¯ç¬¬ä¸€è½®å¯¹è¯ï¼‰"
        print(f"[DEBUG] ===== æµ·ç‹æ¨¡å¼å¯¹è¯å†å²æ£€æŸ¥ =====")
        print(f"[DEBUG] ç”¨æˆ·IP: {user_ip}")
        print(f"[DEBUG] å½“å‰seaking_last_conversationså†…å®¹: {dict(seaking_last_conversations)}")
        print(f"[DEBUG] æœ¬ç”¨æˆ·çš„ä¸Šä¸€è½®å¯¹è¯: {repr(last_conversation)}")
        print(f"[DEBUG] æ˜¯å¦ä¸ºç¬¬ä¸€è½®: {is_first_round}")
        print(f"[DEBUG] ===== å¯¹è¯å†å²æ£€æŸ¥ç»“æŸ =====")
        
        # ç›´æ¥è°ƒç”¨SeakingChain
        ai_response = seaking_chain.run(
            persona=persona_config["persona"],
            user_input=request.message,
            current_score=request.seaking_score,
            challenge_type=persona_config["challenge_type"],
            # ä¼ å…¥æµ·ç‹æ€§åˆ«ã€ç”¨æˆ·æ€§åˆ«
            gender=persona_config["gender"],
            user_gender=persona_config["user_gender"],
            description=persona_config["description"],
            style=persona_config["style"],
            weakness=persona_config["weakness"],
            last_conversation=last_conversation
        )
        
        # ä»AIå›å¤ä¸­è§£æå¾—åˆ†å’Œèƒœåˆ©çŠ¶æ€
        new_score, is_victory = parse_seaking_score(ai_response, request.seaking_score, is_first_round)
        print(f"[DEBUG] æµ·ç‹å¾—åˆ†å¤„ç†ç»“æœ: åŸå¾—åˆ†={request.seaking_score}, æ–°å¾—åˆ†={new_score}, æ˜¯å¦é€šå…³={is_victory}")
        
        # æ£€æŸ¥æ˜¯å¦é€šå…³
        if "ğŸ‰æ­å–œæŒ‘æˆ˜æˆåŠŸ" in ai_response:
            is_victory = True
            new_score = 100
            print(f"[DEBUG] æ£€æµ‹åˆ°é€šå…³æ¶ˆæ¯ï¼Œå¼ºåˆ¶è®¾ç½®å¾—åˆ†ä¸º100")
            # é€šå…³åæ¸…é™¤å¯¹è¯å†å²
            seaking_last_conversations.pop(user_ip, None)
        else:
            # ä¿å­˜å½“å‰å¯¹è¯å†å²ä¾›ä¸‹ä¸€è½®ä½¿ç”¨
            # æ— è®ºæ˜¯å¦ç¬¬ä¸€è½®ï¼Œéƒ½éœ€è¦ä¿å­˜æœ¬è½®å¯¹è¯ç»™ä¸‹è½®ä½¿ç”¨
            
            # æå–æµ·ç‹çš„å›å¤ï¼ˆåœ¨ã€æµ·ç‹ã€‘å’Œã€æ‹½å§æ—ç™½ã€‘ä¹‹é—´çš„å†…å®¹ï¼‰
            seaking_reply = ""
            if "ã€æµ·ç‹ã€‘" in ai_response:
                # æå–æµ·ç‹å›å¤éƒ¨åˆ†
                seaking_part = ai_response.split("ã€æµ·ç‹ã€‘")[1]
                if "ã€æ‹½å§æ—ç™½ã€‘" in seaking_part:
                    seaking_reply = seaking_part.split("ã€æ‹½å§æ—ç™½ã€‘")[0].strip()
                else:
                    seaking_reply = seaking_part.strip()
                # æ¸…ç†æ ¼å¼ï¼Œç§»é™¤äººè®¾åç§°å‰ç¼€
                if "ï¼š" in seaking_reply:
                    seaking_reply = seaking_reply.split("ï¼š", 1)[1].strip()
            
            # ä¿å­˜æ ¼å¼ï¼šæµ·ç‹å›å¤ + ç”¨æˆ·å›å¤
            conversation_record = f"æµ·ç‹ï¼š{seaking_reply}\nç”¨æˆ·ï¼š{request.message}"
            seaking_last_conversations[user_ip] = conversation_record
            print(f"[DEBUG] ===== å¯¹è¯å†å²ä¿å­˜è¯¦æƒ… =====")
            print(f"[DEBUG] ç”¨æˆ·IP: {user_ip}")
            print(f"[DEBUG] æµ·ç‹å›å¤: \"{seaking_reply}\"")
            print(f"[DEBUG] ç”¨æˆ·æ¶ˆæ¯: \"{request.message}\"")
            print(f"[DEBUG] å®Œæ•´å¯¹è¯è®°å½•: \"{conversation_record}\"")
            print(f"[DEBUG] ä¿å­˜åçš„seaking_last_conversations: {dict(seaking_last_conversations)}")
            print(f"[DEBUG] ===== å¯¹è¯å†å²ä¿å­˜å®Œæˆ =====")
        
        # æµ·ç‹å¯¹æˆ˜æ¨¡å¼ä¸æ›´æ–°å…¨å±€è®°å¿†ï¼Œé¿å…å½±å“æ­£å¸¸èŠå¤©
        
        return {
            "response": ai_response,
            "love_brain_index": 0,  # æµ·ç‹å¯¹æˆ˜æ¨¡å¼ä¸‹ä¸è®¡ç®—æ‹çˆ±è„‘æŒ‡æ•°
            "love_brain_level": "æµ·ç‹å¯¹æˆ˜",
            "risk_signals": ["æµ·ç‹å¯¹æˆ˜æ¨¡å¼"],
            "memory_stats": memory_manager.get_memory_stats(),  # ä¿æŒåŸæœ‰è®°å¿†çŠ¶æ€
            "seaking_mode": {
                "button_type": request.button_type,
                "persona": persona_config["persona"],
                "challenge_type": persona_config["challenge_type"],
                "current_score": new_score,
                "is_victory": is_victory,
                "is_first_seaking": False  # æ–°çš„Chainä¸éœ€è¦é¦–æ¬¡å¯¹è¯æ¦‚å¿µ
            },
            "routing_info": {
                "routing_type": "direct_seaking_tool",
                "success": True
            },
            "performance": {
                "token_saved": True,
                "processing_time_ms": 0
            }
        }
        
    except Exception as e:
        print(f"[Error] Seaking mode failed: {e}")
        return {
            "response": "æµ·ç‹å¯¹æˆ˜ç³»ç»Ÿæš‚æ—¶æ•…éšœï¼Œè¯·ç¨åå†è¯•...ğŸš¬",
            "love_brain_index": 0,
            "love_brain_level": "æµ·ç‹å¯¹æˆ˜",
            "risk_signals": [],
            "memory_stats": memory_manager.get_memory_stats(),  # ä¿æŒåŸæœ‰è®°å¿†çŠ¶æ€
            "seaking_mode": {
                "button_type": request.button_type,
                "error": True
            }
        }

def handle_normal_chat(request: ChatRequest, memory_manager, agent):
    """å¤„ç†æ­£å¸¸èŠå¤©æ¨¡å¼ - å…¨åŒæ­¥æ¶æ„ï¼Œç®€åŒ–è®¾è®¡"""
    import time
    
    print(f"[DEBUG] handle_normal_chat è¢«è°ƒç”¨ï¼Œä½¿ç”¨å…¨åŒæ­¥æ¶æ„")
    
    # å¼€å§‹æ€§èƒ½è®¡æ—¶
    start_time = time.time()
    
    # è·å–è®°å¿†ä¸Šä¸‹æ–‡
    memory_context = memory_manager.get_memory_context_for_tool()
    
    # ğŸš€ åŒæ­¥severityåˆ†æ + åŠ¨æ€äººè®¾é€‰æ‹©
    analysis_start = time.time()
    analysis_result = severity_analyzer.analyze_with_answerstyle(request.message, memory_context)
    analysis_time = time.time() - analysis_start
    
    severity_result = SeverityResult(**analysis_result["severity"])
    
    # å‡†å¤‡ä¼ é€’ç»™Agentçš„è¾“å…¥
    if memory_context and memory_context != "æ— å†å²è®°å¿†":
        # æ£€æŸ¥ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œé¿å…è¿‡é•¿
        if len(memory_context) > 200:
            memory_context = memory_context[:197] + "..."
        combined_input = f"è®°å¿†ä¸Šä¸‹æ–‡: {memory_context}\nç”¨æˆ·è¾“å…¥: {request.message}"
    else:
        # æ²¡æœ‰å†å²è®°å¿†æ—¶ï¼Œç›´æ¥ä½¿ç”¨ç”¨æˆ·è¾“å…¥
        combined_input = request.message
    
    # å¦‚æœæ˜¯æµ·ç‹æ¨¡æ‹Ÿæ¨¡å¼ï¼Œæ·»åŠ personaä¿¡æ¯
    if request.persona and request.persona.strip():
        combined_input += f"\n\næµ·ç‹äººè®¾: {request.persona}"
    
    # ğŸ¯ æ„å»ºå¸¦åŠ¨æ€äººè®¾çš„Agent
    agent_build_start = time.time()
    enhanced_agent = build_agent(
        memory_manager=memory_manager,
        answer_style=analysis_result["dynamic_prompt"]
    )
    agent_build_time = time.time() - agent_build_start
    
    # æ³¨æ„ï¼šé¢„åˆ†æç»“æœå·²é€šè¿‡åŠ¨æ€äººè®¾æ³¨å…¥åˆ°Agentçš„system promptä¸­ï¼Œæ— éœ€é‡å¤ä¼ é€’
    
    # ğŸ¯ æ‰§è¡Œå¸¦åŠ¨æ€äººè®¾çš„Agent
    agent_exec_start = time.time()
    result = enhanced_agent.invoke({
        "input": combined_input
    })
    agent_exec_time = time.time() - agent_exec_start
    ai_response = result.get("output", "å¤„ç†å¤±è´¥ï¼Œè¯·é‡è¯•")
    
    # ä½¿ç”¨é¢„åˆ†æç»“æœï¼Œæ— éœ€ä»ä¸­é—´æ­¥éª¤è§£æ
    love_brain_index = severity_result.index
    love_brain_level = severity_result.level
    risk_signals = severity_result.signals
    
    # æ›´æ–°è®°å¿†ä¸­çš„å¯¹è¯è®°å½•
    memory_manager.add_interaction(
        user_input=request.message,
        ai_response=ai_response,
        love_brain_level=love_brain_level,
        risk_signals=risk_signals
    )
    
    # è·å–è®°å¿†ç»Ÿè®¡
    memory_stats = memory_manager.get_memory_stats()
    
    # è®¡ç®—æ€»è€—æ—¶
    total_time = time.time() - start_time
    
    return {
        "response": ai_response,
        "love_brain_index": love_brain_index,
        "love_brain_level": love_brain_level,
        "risk_signals": risk_signals,
        "memory_stats": memory_stats,
        # "severity_analysis": å·²åˆå¹¶åˆ°é¡¶å±‚å­—æ®µï¼Œé¿å…é‡å¤æ•°æ®
        # "answerstyle_used": å‰ç«¯æœªä½¿ç”¨ï¼Œå·²ç§»é™¤é¿å…æ•°æ®å†—ä½™
        "routing_info": {
            "routing_type": "sync_dynamic_persona_agent",
            "success": True
        },
        "performance": {
            "total_time_ms": int(total_time * 1000),
            "analysis_time_ms": int(analysis_time * 1000),
            "agent_build_time_ms": int(agent_build_time * 1000),
            "agent_exec_time_ms": int(agent_exec_time * 1000),
            "architecture": "sync_optimized",
            "routing_efficiency": 1.0
        },
        "debug_info": {} if os.getenv("DEBUG", "false").lower() != "true" else {
            "architecture": "sync_dynamic_persona_agent",
            "memory_type": AppConfig.MEMORY_STORAGE_TYPE,
            "ip_isolation": AppConfig.ENABLE_IP_ISOLATION,
            "pre_analysis_used": severity_result.index > 0,
            "selected_persona_preview": analysis_result["answerstyle"]["roleset"][:50] + "...",
            "performance_breakdown": {
                "analysis_percentage": int((analysis_time / total_time) * 100),
                "agent_build_percentage": int((agent_build_time / total_time) * 100),
                "agent_exec_percentage": int((agent_exec_time / total_time) * 100)
            }
        }
    }

@app.post("/reset")
async def reset_chat(req: Request):
    """é‡ç½®ç«¯ç‚¹ - æ¸…é™¤çŸ­æœŸè®°å¿†"""
    user_ip = get_user_identifier(req)
    
    try:
        user_session = get_memory_manager(user_ip)
        memory_manager = user_session["memory_manager"]
        
        # é‡ç½®è®°å¿†
        memory_manager.clear_session()
        
        # æ¸…é™¤æµ·ç‹å¯¹æˆ˜å†å²
        seaking_last_conversations.pop(user_ip, None)
        
        # é‡æ–°åˆ›å»ºAgent (ç¡®ä¿ä½¿ç”¨æ–°çš„è®°å¿†çŠ¶æ€)
        agent = build_agent(memory_manager)
        user_memory_managers[user_ip]["agent"] = agent
        
        return {
            "message": "ä¼šè¯å·²é‡ç½®ï¼ŒçŸ­æœŸè®°å¿†å·²æ¸…é™¤",
            "memory_stats": memory_manager.get_memory_stats(),
            "routing_enabled": False,
            "architecture": "direct_agent"
        }
    except Exception as e:
        print(f"[Error] Reset failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/system/status")
async def get_system_status(req: Request):
    """ç³»ç»ŸçŠ¶æ€ç«¯ç‚¹ - æ˜¾ç¤ºè·¯ç”±å’Œè®°å¿†çŠ¶æ€"""
    user_ip = get_user_identifier(req)
    
    try:
        user_session = get_memory_manager(user_ip)
        memory_manager = user_session["memory_manager"]
        
        return {
            "status": "running",
            "memory_status": memory_manager.get_memory_stats(),
            "system_config": {
                "enhanced_routing_enabled": False,
                "ip_isolation_enabled": AppConfig.ENABLE_IP_ISOLATION,
                "memory_storage_type": AppConfig.MEMORY_STORAGE_TYPE,
                "debug_mode": os.getenv("DEBUG", "false").lower() == "true"
            }
        }
    except Exception as e:
        print(f"[Error] Status check failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/system/routing/stats")
async def get_routing_stats():
    """è·¯ç”±ç»Ÿè®¡ç«¯ç‚¹ - æ˜¾ç¤ºå…¨å±€è·¯ç”±æ€§èƒ½"""
    try:
        return {
            "total_users": len(user_memory_managers),
            "enhanced_routing_enabled": False,
            "architecture": "direct_agent",
            "per_user_stats": {}
        }
    except Exception as e:
        print(f"[Error] Routing stats failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/memory/stats")
async def get_memory_stats(request: Request):
    """è·å–è®°å¿†ç»Ÿè®¡ä¿¡æ¯ - ä¾›å‰ç«¯è®°å¿†æŒ‰é’®ä½¿ç”¨"""
    try:
        user_ip = get_user_identifier(request)
        user_session = get_memory_manager(user_ip)
        
        # è·å–è®°å¿†ç»Ÿè®¡
        memory_stats = user_session["memory_manager"].get_memory_stats()
        
        return {
            "conversation_count": memory_stats.get("conversation_count", 0),
            "estimated_tokens": memory_stats.get("estimated_tokens", 0),
            "max_tokens": memory_stats.get("max_tokens", 1000),
            "memory_usage_ratio": memory_stats.get("token_usage_ratio", 0),
            "user_patterns": memory_stats.get("user_patterns", {}),
            "pattern_count": memory_stats.get("pattern_count", 0),
            "short_term_count": memory_stats.get("short_term_count", 0),
            "long_term_count": memory_stats.get("long_term_count", 0)
        }
    except Exception as e:
        print(f"[Error] Memory stats failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/memory/summary")
async def get_memory_summary(request: Request):
    """è·å–è®°å¿†è¯¦æƒ…æ‘˜è¦ - ä¾›å‰ç«¯è®°å¿†æŒ‰é’®ç‚¹å‡»æ—¶æ˜¾ç¤º"""
    try:
        user_ip = get_user_identifier(request)
        user_session = get_memory_manager(user_ip)
        
        # è·å–è®°å¿†ç»Ÿè®¡å’Œä¸Šä¸‹æ–‡æ‘˜è¦
        memory_stats = user_session["memory_manager"].get_memory_stats()
        context_summary = user_session["memory_manager"].get_context_summary()
        
        # è·å–é•¿æœŸè®°å¿†è¯¦ç»†ä¿¡æ¯
        long_term_memory = user_session["memory_manager"].long_term_memory
        
        # è·å–ç”¨æˆ·ç”»åƒæ€»ç»“
        user_profile = user_session["memory_manager"].get_user_profile_summary()
        
        return {
            "stats": {
                "conversation_count": memory_stats.get("conversation_count", 0),
                "estimated_tokens": memory_stats.get("estimated_tokens", 0),
                "max_tokens": memory_stats.get("max_tokens", 1000),
                "memory_usage_ratio": memory_stats.get("memory_usage_ratio", 0),
                "user_patterns": memory_stats.get("user_patterns", {}),
                "pattern_count": memory_stats.get("pattern_count", 0),
                "short_term_count": memory_stats.get("short_term_count", 0),
                "long_term_count": memory_stats.get("long_term_count", 0)
            },
            "context_summary": context_summary or "æš‚æ— è®°å¿†ä¸Šä¸‹æ–‡",
            "long_term_details": {
                "risk_history": long_term_memory.get("risk_history", []),
                "user_patterns": long_term_memory.get("user_patterns", {}),
                "key_insights": long_term_memory.get("key_insights", []),
                "persona_preferences": long_term_memory.get("persona_preferences", {})
            },
            "user_profile": user_profile
        }
    except Exception as e:
        print(f"[Error] Memory summary failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/seaking/personas")
async def get_seaking_personas():
    """è·å–æµ·ç‹äººè®¾åº“ - ä¾›å‰ç«¯ä½¿ç”¨"""
    try:
        # ä» JSON æ–‡ä»¶è¯»å–äººè®¾é…ç½®
        personas_file = os.path.join("static", "personas.json")
        with open(personas_file, 'r', encoding='utf-8') as f:
            personas_data = json.load(f)
        
        # ç›´æ¥è¿”å›äººè®¾æ•°æ®ï¼Œä¿æŒä¸å‰ç«¯æœŸæœ›çš„ç»“æ„ä¸€è‡´
        return personas_data
    except Exception as e:
        print(f"[Error] Get seaking personas failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹ - Railwayéƒ¨ç½²éœ€è¦"""
    return {"status": "healthy", "service": "anti-love-brain-agent"}

@app.get("/favicon.ico")
async def favicon():
    return FileResponse('static/favicon.svg')

if __name__ == "__main__":
    import uvicorn
    
    print("ğŸš€ å¯åŠ¨ Anti Love Brain Agent")
    print(f"ğŸ“Š å¢å¼ºè·¯ç”±: {'âœ… å¯ç”¨' if False else 'âŒ ç¦ç”¨'}")
    print(f"ğŸŒ IPéš”ç¦»: {'âœ… å¯ç”¨' if AppConfig.ENABLE_IP_ISOLATION else 'âŒ ç¦ç”¨'}")
    print(f"ğŸ’¾ è®°å¿†å­˜å‚¨: {AppConfig.MEMORY_STORAGE_TYPE}")
    print("-" * 50)
    
    port = int(os.getenv("PORT", 8000))
    uvicorn.run(app, host="0.0.0.0", port=port)
