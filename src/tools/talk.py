from typing import Type, List, Dict, Any, Optional
from pydantic import BaseModel, Field
from langchain.tools import BaseTool
from ..prompts.prompts import TALK_INNER_GUIDE
from ..prompts.prompt_config import TALK_EXECUTION_PROMPT

class TalkInput(BaseModel):
    user_text: str = Field(..., description="ç”¨æˆ·å‘è¨€å†…å®¹")
    memory_context: str = Field(default="", description="ç”±Agentæä¾›çš„è®°å¿†ä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰")

class TalkTool(BaseTool):
    name = "talk_tool"
    description = ("æ—¥å¸¸é—²èŠå·¥å…·ï¼šåªæœ‰ç”¨æˆ·æœŸæœ›éæ‹çˆ±è¯é¢˜çš„æ—¥å¸¸é—²èŠã€å‹æƒ…/äº²æƒ…/èŒåœº/ç¤¾ä¼šè¯é¢˜è®¨è®ºåæ§½æ—¶ï¼Œæ‰ä½¿ç”¨è¯¥å·¥å…·ã€‚")
    args_schema: Type[BaseModel] = TalkInput

    def _run(self, user_text: str, memory_context: str = "", memory_manager=None) -> str:
        """é—ºèœœå¹æ°´æ­å­æ¨¡å¼ - ç›´æ¥è°ƒç”¨LLMç”Ÿæˆå›å¤"""
        try:
            from ..core.config import llm
            
            # æ ¼å¼åŒ–promptæ¨¡æ¿
            formatted_prompt = TALK_EXECUTION_PROMPT.format(
                user_text=user_text,
                talk_guide=TALK_INNER_GUIDE,
            )
            
            # ç›´æ¥è°ƒç”¨LLMç”Ÿæˆå›å¤
            llm_instance = llm(temperature=0.1)
            response = llm_instance.invoke(formatted_prompt)
            
            # è¿”å›ç”Ÿæˆçš„å›å¤å†…å®¹
            return response.content if hasattr(response, 'content') else str(response)
            
        except Exception as e:
            # é™çº§å¤„ç†ï¼šè¿”å›ç®€å•å›å¤
            return f"å§æ²¡é’±äº†ï¼Œå¿™ç€æ‰“å·¥èµšè‰æ–™ï¼æ™šç‚¹å†èŠå§é“å­ï¼ğŸ˜­"

    def _arun(self, *args, **kwargs):
        raise NotImplementedError
