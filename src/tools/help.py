from typing import Type
from pydantic import BaseModel, Field
from langchain.tools import BaseTool
from ..prompts.prompts import HELP_INNER_GUIDE
from ..prompts.prompt_config import HELP_EXECUTION_PROMPT


class HelpInput(BaseModel):
    user_text: str = Field(..., description="ç”¨æˆ·å‘è¨€")
    memory_context: str = Field(default="", description="ç”±Agentæä¾›çš„è®°å¿†ä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰")

class HelpTool(BaseTool):
    name = "help_tool"
    description = ("æƒ…æ„Ÿæ±‚åŠ©åˆ†æå·¥å…·ï¼šåªæœ‰ç”¨æˆ·æœ‰æ˜¾è‘—çš„æƒ…æ„Ÿæ±‚åŠ©æ„å›¾æˆ–æ‹çˆ±è„‘ä¸¥é‡ç¨‹åº¦ä¸ºã€å±é™©ã€‘ç­‰çº§åœºæ™¯ï¼Œæ‰ä½¿ç”¨è¯¥å·¥å…·è¾“å‡ºæƒ…æ„Ÿå’¨è¯¢ä¸“å®¶çš„å»ºè®®ã€‚")
    args_schema: Type[BaseModel] = HelpInput

    def _run(self, user_text: str, memory_context: str = "") -> str:
        """æƒ…æ„Ÿæ±‚åŠ©åˆ†æå·¥å…· - ç›´æ¥è°ƒç”¨LLMç”Ÿæˆå›å¤"""
        try:
            from ..core.config import llm
            
            # æ ¼å¼åŒ–promptæ¨¡æ¿
            formatted_prompt = HELP_EXECUTION_PROMPT.format(
                user_text=user_text,
                evidence="",  # æœç´¢åŠŸèƒ½å·²ç§»é™¤ï¼Œevidenceä¸ºç©º
                help_guide=HELP_INNER_GUIDE,
            )
            
            # ç›´æ¥è°ƒç”¨LLMç”Ÿæˆå›å¤
            llm_instance = llm(temperature=0.1)
            response = llm_instance.invoke(formatted_prompt)
            
            # è¿”å›ç”Ÿæˆçš„å›å¤å†…å®¹
            return response.content if hasattr(response, 'content') else str(response)
            
        except Exception as e:
            return f"å§å¦¹å•Šï¼Œå§è„‘å­æš‚æ—¶å®•æœºäº†ğŸš¬ç­‰æˆ‘ç¼“ç¼“å…ˆï¼"

    def _arun(self, *args, **kwargs):
        raise NotImplementedError
