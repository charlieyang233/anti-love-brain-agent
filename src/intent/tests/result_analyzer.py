#!/usr/bin/env python3
"""
è·¯ç”±æµ‹è¯•ç»“æœåˆ†æå™¨ - æ·±åº¦åˆ†ææµ‹è¯•ç»“æœ
"""

import json
import sys
from collections import Counter, defaultdict
from typing import Dict, List, Any


def analyze_test_results(filename: str):
    """åˆ†ææµ‹è¯•ç»“æœ"""
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return
    
    print("ğŸ“Š è¯¦ç»†è·¯ç”±æµ‹è¯•ç»“æœåˆ†æ")
    print("=" * 80)
    
    detailed_results = data.get("detailed_results", [])
    
    # é‡æ–°è®¡ç®—æ­£ç¡®çš„ç»Ÿè®¡æ•°æ®
    successful_tests = [r for r in detailed_results if r["success"]]
    
    # è·¯ç”±è·¯å¾„ç»Ÿè®¡
    routing_paths = [r["routing_info"].get("path", "unknown") for r in successful_tests]
    path_counter = Counter(routing_paths)
    
    print(f"ğŸ›¤ï¸  è·¯ç”±è·¯å¾„è¯¦ç»†åˆ†æ:")
    total_success = len(successful_tests)
    for path, count in path_counter.most_common():
        percentage = count / total_success * 100
        print(f"  {path:20s}: {count:2d}æ¬¡ ({percentage:5.1f}%)")
    
    # å·¥å…·è°ƒç”¨ç»Ÿè®¡
    all_tools = []
    for r in successful_tests:
        tools = r["routing_info"].get("tools_called", [])
        all_tools.extend(tools)
    
    tool_counter = Counter(all_tools)
    print(f"\nğŸ”§ å·¥å…·è°ƒç”¨è¯¦ç»†åˆ†æ:")
    for tool, count in tool_counter.most_common():
        percentage = count / len(all_tools) * 100 if all_tools else 0
        print(f"  {tool:20s}: {count:2d}æ¬¡ ({percentage:5.1f}%)")
    
    # TokenèŠ‚çœåˆ†æ
    token_saved_tests = [r for r in successful_tests 
                        if r["performance"].get("token_saved", False)]
    token_savings_rate = len(token_saved_tests) / total_success if total_success > 0 else 0
    
    print(f"\nğŸ’° TokenèŠ‚çœè¯¦ç»†åˆ†æ:")
    print(f"  èŠ‚çœæˆåŠŸ: {len(token_saved_tests):2d}æ¬¡")
    print(f"  æ€»æµ‹è¯•æ•°: {total_success:2d}æ¬¡")
    print(f"  èŠ‚çœç‡:   {token_savings_rate:5.1%}")
    
    print(f"\n  TokenèŠ‚çœçš„è¯·æ±‚:")
    for r in token_saved_tests:
        tools = ', '.join(r["routing_info"].get("tools_called", []))
        print(f"    â€¢ {r['input'][:40]:40s} -> {tools}")
    
    # åˆ†ç±»å‡†ç¡®æ€§åˆ†æ
    print(f"\nğŸ¯ åˆ†ç±»å‡†ç¡®æ€§è¯¦ç»†åˆ†æ:")
    
    categories = {
        "æµ·ç‹ç±»": ["æµ·ç‹", "æ’©å¦¹", "PUA", "è¯æœ¯"],
        "é£é™©ç±»": ["å¨èƒ", "æš´åŠ›", "æ§åˆ¶"],
        "æ‹çˆ±ç±»": ["ç”·æœ‹å‹", "æœ‹å‹", "å‡ºè½¨", "åŠˆè…¿", "æ¸£ç”·"],
        "èŒåœºç±»": ["åŒäº‹", "è€æ¿", "å·¥ä½œ", "åŠ ç­"],
        "æœç´¢ç±»": ["æœç´¢"],
        "æ—¥å¸¸ç±»": ["å¿ƒæƒ…", "å¤©æ°”"]
    }
    
    expected_tools = {
        "æµ·ç‹ç±»": ["seaking_tool"],
        "é£é™©ç±»": ["help_tool", "search_tool"],
        "æ‹çˆ±ç±»": ["roast_tool", "severity_analyzer"],
        "èŒåœºç±»": ["talk_tool"],
        "æœç´¢ç±»": ["search_tool"],
        "æ—¥å¸¸ç±»": ["talk_tool", "original_agent"]
    }
    
    for category, keywords in categories.items():
        # æ‰¾åˆ°å±äºè¯¥ç±»åˆ«çš„æµ‹è¯•
        category_tests = []
        for r in successful_tests:
            if any(keyword in r["input"] for keyword in keywords):
                category_tests.append(r)
        
        if not category_tests:
            continue
            
        print(f"\n  {category} ({len(category_tests)}ä¸ªæµ‹è¯•):")
        
        # åˆ†æè·¯ç”±å‡†ç¡®æ€§
        expected_tools_for_category = expected_tools.get(category, [])
        correct_routes = 0
        
        for r in category_tests:
            input_text = r["input"]
            actual_tools = r["routing_info"].get("tools_called", [])
            routing_path = r["routing_info"].get("path", "unknown")
            token_saved = r["performance"].get("token_saved", False)
            
            # æ£€æŸ¥æ˜¯å¦è·¯ç”±æ­£ç¡®
            is_correct = any(tool in actual_tools for tool in expected_tools_for_category)
            if is_correct:
                correct_routes += 1
                status = "âœ…"
            else:
                status = "âŒ"
            
            tools_str = ', '.join(actual_tools)
            print(f"    {status} {input_text[:35]:35s} -> {routing_path:10s} ({tools_str}) {'ğŸ’°' if token_saved else ''}")
        
        accuracy = correct_routes / len(category_tests) if category_tests else 0
        print(f"    å‡†ç¡®ç‡: {correct_routes}/{len(category_tests)} ({accuracy:.1%})")
    
    # æ€§èƒ½åˆ†æ
    processing_times = [r["processing_time_ms"] for r in successful_tests]
    avg_time = sum(processing_times) / len(processing_times) if processing_times else 0
    
    print(f"\nâ±ï¸  æ€§èƒ½è¯¦ç»†åˆ†æ:")
    print(f"  å¹³å‡å“åº”æ—¶é—´: {avg_time:.1f}ms")
    print(f"  æœ€å¿«å“åº”:     {min(processing_times):.1f}ms" if processing_times else "  æœ€å¿«å“åº”:     N/A")
    print(f"  æœ€æ…¢å“åº”:     {max(processing_times):.1f}ms" if processing_times else "  æœ€æ…¢å“åº”:     N/A")
    
    # æŒ‰è·¯ç”±è·¯å¾„åˆ†ææ€§èƒ½
    path_times = defaultdict(list)
    for r in successful_tests:
        path = r["routing_info"].get("path", "unknown")
        path_times[path].append(r["processing_time_ms"])
    
    print(f"\n  æŒ‰è·¯ç”±è·¯å¾„åˆ†æ:")
    for path, times in path_times.items():
        avg_path_time = sum(times) / len(times)
        print(f"    {path:15s}: å¹³å‡ {avg_path_time:6.1f}ms (å…±{len(times)}æ¬¡)")
    
    # è®¡ç®—æ­£ç¡®çš„ç»¼åˆè¯„åˆ†
    direct_rate = path_counter.get("direct", 0) / total_success
    agent_rate = path_counter.get("agent_fallback", 0) / total_success
    success_rate = len(successful_tests) / len(detailed_results)
    
    print(f"\nğŸ† é‡æ–°è®¡ç®—çš„ç»¼åˆè¯„åˆ†:")
    print(f"  ç›´æ¥è·¯ç”±ç‡: {direct_rate:.1%}")
    print(f"  Agentå…œåº•ç‡: {agent_rate:.1%}")
    print(f"  TokenèŠ‚çœç‡: {token_savings_rate:.1%}")
    print(f"  ç³»ç»ŸæˆåŠŸç‡: {success_rate:.1%}")
    
    # æ­£ç¡®çš„ç»¼åˆå¾—åˆ†è®¡ç®—
    score = (
        direct_rate * 40 +         # ç›´æ¥è·¯ç”±æƒé‡40%
        token_savings_rate * 30 +  # TokenèŠ‚çœæƒé‡30%
        success_rate * 20 +        # æˆåŠŸç‡æƒé‡20%
        (1 - agent_rate) * 10      # å‡å°‘å…œåº•æƒé‡10%
    ) * 100
    
    print(f"  ç»¼åˆå¾—åˆ†: {score:.1f}/100")
    
    # æ”¹è¿›å»ºè®®
    print(f"\nğŸ’¡ æ”¹è¿›å»ºè®®:")
    
    if direct_rate < 0.7:
        print(f"  â€¢ ç›´æ¥è·¯ç”±ç‡åä½({direct_rate:.1%})ï¼Œå»ºè®®ä¼˜åŒ–æ„å›¾è¯†åˆ«è§„åˆ™")
    
    if token_savings_rate < 0.5:
        print(f"  â€¢ TokenèŠ‚çœç‡åä½({token_savings_rate:.1%})ï¼Œå»ºè®®å¢åŠ æ›´å¤šç›´æ¥è·¯ç”±è§„åˆ™")
    
    if agent_rate > 0.3:
        print(f"  â€¢ Agentå…œåº•ç‡è¿‡é«˜({agent_rate:.1%})ï¼Œå»ºè®®æ‰©å±•è·¯ç”±è¦†ç›–èŒƒå›´")
    
    # æ‰¾å‡ºé—®é¢˜æ¡ˆä¾‹
    problem_cases = [r for r in successful_tests 
                    if r["routing_info"].get("path") == "agent_fallback"]
    
    if problem_cases:
        print(f"\nğŸš¨ éœ€è¦ä¼˜åŒ–çš„Agentå…œåº•æ¡ˆä¾‹:")
        for r in problem_cases[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
            print(f"  â€¢ {r['input']}")


if __name__ == "__main__":
    if len(sys.argv) > 1:
        filename = sys.argv[1]
    else:
        # ä½¿ç”¨æœ€æ–°çš„æµ‹è¯•ç»“æœæ–‡ä»¶
        filename = "routing_test_results_20250814_182147.json"
    
    analyze_test_results(filename)
